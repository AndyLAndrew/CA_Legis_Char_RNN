{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Final Assignment (Prompt 2) COGS 185\n",
    "## Contributors:\n",
    "- Andrew Lona\n",
    "\n",
    "## Project Prompt (3)\n",
    "Option 3: Collecting CA Legislature dataset and trying to produce meaningful results by using the char rnn model.\n",
    "\n",
    "Larger than 1,500 word essay containing\n",
    "- abstract\n",
    "- introduction\n",
    "- method\n",
    "- experiment\n",
    "- conclusion\n",
    "- references\n",
    "\n",
    "Bonus Points Possibilities (must be included as separate section):\n",
    "\n",
    "- Novel ideas and applications\n",
    "- Large efforts in own data collection/preparation\n",
    "- state-of-the-art results on applications\n",
    "- new algorithms or neural network architectures\n",
    "\n",
    "## Goal for this project\n",
    "The goal is to develop a Char RNN model pipeline which can be easily tweaked and scored for creating accurate generative text for Legislative text.\n",
    "\n",
    "## Motivation for this project\n",
    "Based on my sort of personal project for the past year, I aim to develop usable pipelines which can assist others in better understanding complex legal language contained without our governmental systems, such as the California Legislature. Creating a Char RNN model to conduct next-word prediction for bill language could possibly help us understand what words, phrases, sentences and bills would most likely lead to the most complex form of language. Such as if we generate predictions on complex language to see if that carries on.\n",
    "\n",
    "Other motivations for this (related to the bonus portion) is that with an interactive, easy-to-use interface, researchers could easily train Char RNN models on any subset of data within the california legislature in order to better understand legal trends between certain dates, or figure any differences among assembly bills and senate bill types. The possibilities are definitely beyond the scope of my own imagination, but having a rough setup for less experienced researchers would be very helpful. As such, output of the model performance along with multiple tweaking parameters are a must for any interface.\n",
    "\n",
    "## Literature Review, detailing the need/importance of legalese simplification, along with background research into the topic which should potentially speed up progress.\n",
    "- *Poor writing, not specialized concepts, drives processing difficulty in legal language* (Martinez, et al., 2022)\n",
    "    - Details how legalese comprehension difficulty is not just noticeable, but directly tied to poor writing practices. Provides framework for testing and goals for scaling readability.\n",
    "- *Plain English Summarization of Contracts* (Manor and Li, 2019)\n",
    "    - An earlier attempt at legalese simplification, albeit with a simpler model and more statistically rigid readability scoring criteria. Also says \"this is a very challenging task\" (p. 2)\n",
    "\n",
    "### Python Code Integration Process. Both in code and as a brief writeup of process + results.\n",
    "- The pipeline will follow this process in the code below...\n",
    "\n",
    "1. The user is asked to general parameters for bills they would like scraped from the CA Legislature website\n",
    "2. Bill text is organized into a dataframe rows and saved as a csv and/or text file.\n",
    "4. User is able to then generate a Char RNN using said dataframe of bill texts (if not, the process ends here)\n",
    "    - similar to the bill scraper params, Char RNN params can be adjusted using the UI. Default params are given.\n",
    "        - Seq length = 128\n",
    "        - Start and End are random\n",
    "        - Training Iterations = 10000\n",
    "5. Once Char RNN completes, results are automatically generated and the user is now allowed to generate predictions from said model from the UI\n",
    "    - An Applescript function will let users be notified once the model is finished training.\n",
    "## Brief analysis of results\n",
    "- The Char RNN itself will be evauluated utilizing the first 5 bills from each year range for all SB/ABs using the webscraper process, leading to a full dataset of [].\n",
    "- The UI itself will be shown to a few potential users for input on usage.\n",
    "    - 2 PoliSci PhD Students\n",
    "    - 2 Masters Students\n",
    "    - 2 Undergraduate or Recent Undergrad Students\n",
    "    - 2 High School Students\n",
    "    - 2 General Population (more than 5+ years from any education)\n",
    "\n",
    "## What would success be at the end of this pipeline?\n",
    "- On a very simple-level, success would be both a simple interface with a working Char RNN that can be reliably trained using any subset of data from the CA Legislature\n",
    "- Reliably trained Char RNN means a model that can deliver decent results with the full date range data sample at 70% or more.\n",
    "    - The good news with the integrated pipeline is that we could retrain with new data over and over.\n",
    "- Because the purpose of this project is to deliver a tool for potential researchers to better explore the difficult-to-navigate legal language contained within the CA legislature, users themselves must be satisfied with the interface and can navigate it without assistance.\n",
    "___"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Dividing Code Block. This is left here as a buffer to help with exporting\n",
    "# Andy -06_08_2023"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "# for data processing\n",
    "import string\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# for pytorch/modeling\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# setting device type\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "\n",
    "# for webscraping\n",
    "from bs4 import BeautifulSoup # Importing BS\n",
    "import requests # and requests to do web scraping of CA Legislature\n",
    "\n",
    "# For GUI\n",
    "import PySimpleGUI as sg #GUI library\n",
    "\n",
    "# Set the custom theme using defined colors\n",
    "custom_theme = {\n",
    "    'BACKGROUND': '#2c2c2c',\n",
    "    'TEXT': '#e6e6e6',\n",
    "    'INPUT': '#3a3a3a',\n",
    "    'TEXT_INPUT': '#e6e6e6',\n",
    "    'SCROLL': '#3a3a3a',\n",
    "    'BUTTON': ('#e6e6e6', '#646464'),\n",
    "    'BORDER': 1,\n",
    "    'SLIDER_DEPTH': 0,\n",
    "    'PROGRESS_DEPTH': 0,\n",
    "    'PROGRESS': ('#01826B', '#D0D0D0'),\n",
    "    'ACCENT1': ('#000000', '#a0a0a0'),\n",
    "    'ACCENT2': ('#000000', '#d0d0d0'),\n",
    "    'ACCENT3': ('#000000', '#f0f0f0'),\n",
    "}\n",
    "\n",
    "sg.theme_add_new('CustomTheme', custom_theme)\n",
    "\n",
    "\n",
    "# multithreading\n",
    "import threading # needed as GUI will freeze up if everything is running on the main thread\n",
    "\n",
    "# used for testing user interaction-based functions, unused in final code\n",
    "import time, sys\n",
    "# time.sleep(2.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. User asked to input quote and what they would like it simplified to.\n",
    "- I managed to make get a GUI working (my first time wow)!\n",
    "- This will be called as a function at the bottom..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Using the quote to webscrape the bill\n",
    "- Simple function used to create structured url to search for the exact bill\n",
    "- If the exact bill is not found, return an error asking user to try correcting their input\n",
    "- If the exact bill is found, scrape the entire bill and prep for use in Step 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def ca_legis_scrape_init(house_type, first_year, last_year, debug=False):\n",
    "    # Some explanation below\n",
    "    # What I've learned of the url and search structure from CA Legislature\n",
    "    # The base url is this chunk:\n",
    "    base_search_url =  \"https://leginfo.legislature.ca.gov/faces/billSearchClient.xhtml?\"\n",
    "\n",
    "    # The session chunk is:\n",
    "    #year_start_year_end = str(20212022) #all sessions from 1999 to 2022 [sessions are two year pairs ended with 2021-2022]\n",
    "    #session_chunk = \"session_year=\"+ year_start_year_end\n",
    "    # so for the start and end sessions, we want a list of all sessions desired...\n",
    "    first_start, first_end = map(int, first_year.split(\"-\"))\n",
    "    last_start, last_end = map(int, last_year.split(\"-\"))\n",
    "\n",
    "    years = [\"session_year=\" + str(year) + str(year + 1) for year in range(first_start, last_end + 1, 2)]\n",
    "    if len(years) == 0 :\n",
    "        print(\"check work for years\")\n",
    "        exit() #return None\n",
    "    # Note: session years searches do not work for all years when using phrase search which is why for now\n",
    "    # phrase searching is disabled\n",
    "\n",
    "    # The keyword/search term chunk is: &keyword=test\n",
    "    # Clearly states to surround the phrase in quotes\n",
    "    # We are avoiding this as it's equivalent to Title String Contains Searching Internally\n",
    "\n",
    "    # The house search term chunk is: &house=Both\n",
    "    if house_type == \"Both\":\n",
    "        house_type = (\"&house=\" + \"Both\")\n",
    "    elif house_type == \"Senate\":\n",
    "        house_type = (\"&house=\" + \"Senate\")\n",
    "    else:\n",
    "        house_type = (\"&house=\" + \"Assembly\")\n",
    "\n",
    "    # The author search term chunk is: &author=All\n",
    "    author = (\"&author=\" + \"All\") # for now we have to use all authors\n",
    "\n",
    "    # and The law code search term chunk is: &lawCode=All\n",
    "    law = (\"&lawcode=\" + \"All\") # same thing for law\n",
    "    law_chunk =  law\n",
    "\n",
    "    # a big issue is being able to pull the lists and saving them. Trying to navigate\n",
    "    # their html/css objects to figure this out but for the sake of time I am leaving\n",
    "    # that to the very end if I even have a chance.\n",
    "\n",
    "    # --------------------- SCRAPING + DF INITIALIZATION LOOP FOR DATA ---------------------\n",
    "\n",
    "    # Creating url search string to try checking all years\n",
    "    column_names = ['Bill', 'Title', 'Author', 'Status', 'Session', 'Type']\n",
    "    scrape_data = [] # generating temporary df to store table items\n",
    "\n",
    "    for year_pair in years: # for each pair of years\n",
    "        full_search_url = base_search_url + year_pair + house_type + author + law_chunk # creating url\n",
    "        response = requests.get(url = full_search_url) # waiting for response from Legislature website\n",
    "        soup = BeautifulSoup(response.content, 'html.parser') # creating soup from response\n",
    "\n",
    "        for tr in soup.find(id='bill_results').find_all('tr'): # for each item in the table\n",
    "            row = [td.text for td in tr.find_all('td')] # store them in a row\n",
    "            if len(row) != 0: # accounting for first entry in table object which is Null\n",
    "                row.append(year_pair.replace('session_year=', '')) # adding session years\n",
    "                row[0] = row[0].strip().rstrip('\\n').replace('-', '') # cleaning Bill for easier url building\n",
    "                row.append(re.search(r'([A-Z]+)', row[0]).group(1)) # adding bill type\n",
    "                scrape_data.append(row)\n",
    "\n",
    "\n",
    "    scrape_data = pd.DataFrame(scrape_data, columns=column_names) # generate df with these rows\n",
    "    # scrape_data['Bill'] = scrape_data['Bill'].str.strip().str.rstrip('\\n') # cleaning\n",
    "    # scrape_data['Bill'] = scrape_data['Bill'].str.replace('-', '') # more cleaning\n",
    "\n",
    "    # Drop the rows with \"X\" bill referrals (these are repeats)\n",
    "    scrape_data = scrape_data[~scrape_data['Bill'].str.contains('X')] # Drop the rows that contain the character\n",
    "    # Reset the index\n",
    "    scrape_data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # sending to next step\n",
    "    return scrape_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def text_cleaner(link):\n",
    "    response = requests.get(url = link) # waiting for response from Legislature website using new url\n",
    "    soup = BeautifulSoup(response.content, 'html.parser') # creating soup from response of new url\n",
    "    soup_bill = soup.body.find(id=\"content_main\").find(id=\"centercolumn\").find(id=\"bill_all\") # locate bill location\n",
    "    text_content = soup_bill.get_text() # get bill text\n",
    "    text_content = re.sub(r'\\s+', ' ', text_content) # regex processing for extra spaces\n",
    "    text_content = re.sub(r'\\\\[a-z0-9]{2}', '', text_content) # regex processing for string formatting\n",
    "    return text_content"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# string to int\n",
    "def convert_to_int(value):\n",
    "    try:\n",
    "        value = int(value)\n",
    "        return value\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "# string to float\n",
    "def convert_to_float(value):\n",
    "    try:\n",
    "        value = float(value)\n",
    "        return value\n",
    "    except (ValueError, TypeError):\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def ca_legis_scrape_content(init_df, bill_num, text):\n",
    "    if bill_num == '': bill_num = len(init_df) # if user inputted nothing\n",
    "\n",
    "    try: # bill_num convert to int\n",
    "        bill_num = int(bill_num)\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "    # start of true function\n",
    "    if text != \"\": # if the user specifies a search term (handled the same as CA Legis Website)\n",
    "        init_df = init_df[init_df['Title'].str.contains(text)]\n",
    "        init_df.reset_index(inplace=True, drop=True)\n",
    "    if len(init_df) == 0: return None # no possible search\n",
    "\n",
    "    # --------------------- SCRAPING TEXT LOOP ---------------------\n",
    "    # now we need to prep our mass bill scraping\n",
    "    bill_content_url = \"https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=\"\n",
    "    bill_content = []\n",
    "\n",
    "    for bill, session_year, b_type, limit in zip(init_df['Bill'], init_df['Session'], init_df['Type'], range(0, bill_num)): # for each row\n",
    "        current_url = bill_content_url + session_year + '0' + bill # creating url\n",
    "        bill_content.append(text_cleaner(link=current_url)) # web scrape + text cleaning function\n",
    "        if limit == bill_num: break # if user specifies a certain scrap limit, end loop\n",
    "\n",
    "    if bill_num < len(init_df): init_df = init_df.loc[0:(bill_num-1)].copy() # slicing if needed\n",
    "    init_df[\"Text\"] = bill_content # writing to df\n",
    "\n",
    "    return init_df # sending back"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# concatenates Bill Text\n",
    "def concatenate_column(df_to_rip):\n",
    "    column_values = df_to_rip[\"Text\"].astype(str)  # Convert column to string type\n",
    "    concatenated_string = ''.join(column_values)\n",
    "    return concatenated_string\n",
    "\n",
    "# Get a random sequence of the bill dataset.\n",
    "def get_random_seq(file_length, file, user_seq_length):\n",
    "    seq_len     = user_seq_length  # The length of an input sequence.\n",
    "    start_index = random.randint(0, file_length - seq_len)\n",
    "    end_index   = start_index + seq_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "# Convert the sequence to one-hot tensor.\n",
    "def seq_to_onehot(seq, all_chars, num_chars):\n",
    "    tensor = torch.zeros(len(seq), 1, num_chars)\n",
    "    # Shape of the tensor:\n",
    "    #     (sequence length, batch size, classes)\n",
    "    # Here we use batch size = 1 and classes = number of unique characters.\n",
    "    for t, char in enumerate(seq):\n",
    "        index = all_chars.index(char)\n",
    "        tensor[t][0][index] = 1\n",
    "    return tensor\n",
    "\n",
    "# Convert the sequence to index tensor.\n",
    "def seq_to_index(seq, all_chars):\n",
    "    tensor = torch.zeros(len(seq), 1)\n",
    "    # Shape of the tensor:\n",
    "    #     (sequence length, batch size).\n",
    "    # Here we use batch size = 1.\n",
    "    for t, char in enumerate(seq):\n",
    "        tensor[t] = all_chars.index(char)\n",
    "    return tensor\n",
    "\n",
    "# Sample a mini-batch including input tensor and target tensor.\n",
    "def get_input_and_target(file, file_length, all_chars, num_chars, user_seq_length):\n",
    "    seq    = get_random_seq(file = file, file_length = file_length, user_seq_length = user_seq_length)\n",
    "    input  = seq_to_onehot(seq[:-1], all_chars = all_chars, num_chars = num_chars)      # Input is represented in one-hot.\n",
    "    target = seq_to_index(seq[1:], all_chars = all_chars).long() # Target is represented in index.\n",
    "    return input, target\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         # Initialization.\n",
    "#         super(Net, self).__init__()\n",
    "#         self.input_size  = None   # Input size: Number of unique chars.\n",
    "#         self.hidden_size = None   # Hidden size: 100. (default)\n",
    "#         self.output_size = None   # Output size: Number of unique chars.\n",
    "#\n",
    "#         ###### To be filled ######\n",
    "#         self.rnn_cell = nn.RNNCell(self.input_size, self.hidden_size)\n",
    "#         self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "#         ###### To be filled ######\n",
    "#\n",
    "#     def set_n_chars(self, n_chars): # to allow for this threading madness to continue\n",
    "#         self.input_size = n_chars\n",
    "#         self.output_size = n_chars\n",
    "#\n",
    "#     def set_hidden_size(self, hidden_size): # to allow for this threading madness to continue\n",
    "#         self.hidden_size = hidden_size\n",
    "#\n",
    "#     def forward(self, input, hidden):\n",
    "#         \"\"\" Forward function.\n",
    "#               input:  One-hot input. It refers to the x_t in homework write-up.\n",
    "#               hidden: Previous hidden state. It refers to the h_{t-1}.\n",
    "#             Returns (output, hidden) where output refers to y_t and\n",
    "#                      hidden refers to h_t.\n",
    "#         \"\"\"\n",
    "#         # Forward function.\n",
    "#         hidden = torch.tanh(self.rnn_cell(input, hidden))###### To be filled ######\n",
    "#         output = self.linear(hidden)###### To be filled ######\n",
    "#\n",
    "#         return output, hidden\n",
    "#\n",
    "#     def init_hidden(self):\n",
    "#         # Initial hidden state.\n",
    "#         # 1 means batch size = 1.\n",
    "#         return torch.zeros(1, self.hidden_size).to(device)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.input_size = None\n",
    "        self.hidden_size = None\n",
    "        self.output_size = None\n",
    "        self.rnn_cell = None\n",
    "        self.linear = None\n",
    "\n",
    "    def set_n_chars(self, n_chars):\n",
    "        self.input_size = n_chars\n",
    "        self.output_size = n_chars\n",
    "        self.initialize_rnn_cell()\n",
    "\n",
    "    def set_hidden_size(self, hidden_size):\n",
    "        self.hidden_size = hidden_size\n",
    "        self.initialize_rnn_cell()\n",
    "\n",
    "    def initialize_rnn_cell(self):\n",
    "        if self.input_size is not None and self.hidden_size is not None:\n",
    "            self.rnn_cell = nn.RNNCell(self.input_size, self.hidden_size)\n",
    "            self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        hidden = torch.relu(self.rnn_cell(input, hidden))\n",
    "        output = self.linear(hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Training step function.\n",
    "def train_step(net, opt, input, target, loss_func):\n",
    "    \"\"\" Training step.\n",
    "        net:    The network instance.\n",
    "        opt:    The optimizer instance.\n",
    "        input:  Input tensor.  Shape: [seq_len, 1, n_chars].\n",
    "        target: Target tensor. Shape: [seq_len, 1].\n",
    "    \"\"\"\n",
    "    seq_len = input.shape[0]    # Get the sequence length of current input.\n",
    "    hidden = net.init_hidden()  # Initial hidden state.\n",
    "    net.zero_grad()             # Clear the gradient.\n",
    "    loss = 0                    # Initial loss.\n",
    "\n",
    "    for t in range(seq_len):    # For each one in the input sequence.\n",
    "        output, hidden = net(input[t], hidden)\n",
    "        loss += loss_func(output, target[t])\n",
    "\n",
    "    loss.backward()             # Backward.\n",
    "    opt.step()                  # Update the weights.\n",
    "\n",
    "    return loss / seq_len       # Return the average loss w.r.t sequence length.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Evaluation step function.\n",
    "def eval_step(net, all_chars, num_chars, init_seq='W', predicted_len=100, gui=False):\n",
    "    # Initialize the hidden state, input and the predicted sequence.\n",
    "    hidden        = net.init_hidden()\n",
    "    init_input    = seq_to_onehot(init_seq, all_chars = all_chars, num_chars = num_chars).to(device)\n",
    "    predicted_seq = init_seq\n",
    "\n",
    "    # Use initial string to \"build up\" hidden state.\n",
    "    for t in range(len(init_seq) - 1):\n",
    "        output, hidden = net(init_input[t], hidden)\n",
    "\n",
    "    # Set current input as the last character of the initial string.\n",
    "    input = init_input[-1]\n",
    "\n",
    "    # Predict more characters after the initial string.\n",
    "    for t in range(predicted_len):\n",
    "        # Get the current output and hidden state.\n",
    "        output, hidden = net(input, hidden)\n",
    "\n",
    "        # Sample from the output as a multinomial distribution.\n",
    "        predicted_index = torch.multinomial(output.view(-1).exp(), 1)[0]\n",
    "\n",
    "        # Add predicted character to the sequence and use it as next input.\n",
    "        predicted_char  = all_chars[predicted_index]\n",
    "        predicted_seq  += predicted_char\n",
    "\n",
    "        # Use the predicted character to generate the input of next round.\n",
    "        input = seq_to_onehot(predicted_char, all_chars = all_chars, num_chars = num_chars)[0].to(device)\n",
    "\n",
    "    if gui:\n",
    "        print(predicted_seq)\n",
    "    else:\n",
    "        return predicted_seq\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# to save txt file\n",
    "def save_string_to_file(string, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(string)\n",
    "\n",
    "# optimizer and loss functions set by user\n",
    "def get_optimizer(user_optimizer, user_lr, net):\n",
    "    if user_optimizer == 'Adam':\n",
    "        return torch.optim.Adam(net.parameters(), lr=user_lr)\n",
    "    elif user_optimizer == 'SGD':\n",
    "        return torch.optim.SGD(net.parameters(), lr=user_lr)\n",
    "    elif user_optimizer == 'RMS Prop':\n",
    "        return torch.optim.RMSprop(net.parameters(), lr=user_lr)\n",
    "    elif user_optimizer == 'Adagrad':\n",
    "        return torch.optim.Adagrad(net.parameters(), lr=user_lr)\n",
    "\n",
    "# I know we can't use different loss functions rn, this is meant for future uses for\n",
    "# me. Kind of like having a GUI to easily model text data.\n",
    "\n",
    "def get_loss_function(user_loss_func):\n",
    "    if user_loss_func == 'Cross Entropy':\n",
    "        return nn.CrossEntropyLoss()\n",
    "#     elif user_loss_func == 'NLL':\n",
    "#         return nn.NLLLoss()\n",
    "#     elif user_loss_func == 'BCE With Logits':\n",
    "#         return nn.BCEWithLogitsLoss()\n",
    "#     elif user_loss_func == 'CTC':\n",
    "#         return nn.CTCLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Global variables!\n",
    "total = 100     # Max size of progress bar\n",
    "message = ''    # Blank message string, used to send throughout functions and threads. Not needed yet\n",
    "progress = 0    # current progress up to a maximum of \"total\"\n",
    "\n",
    "def long_operation_thread_scraping(house, start_year, end_year, max_bills, search):\n",
    "    global message, progress\n",
    "\n",
    "    # Webscraping into dataframe func\n",
    "    bill_df = ca_legis_scrape_init(house_type = house, first_year = start_year, last_year = end_year) # bills_df comes as dict with all bills found\n",
    "    if bill_df is None: raise Exception(\"Error in your parameter input, are your year ranges making sense?\\nDouble check to make sure everything looks okay.\")\n",
    "    progress += 30 # progress bar increase\n",
    "\n",
    "    bill_df = ca_legis_scrape_content(init_df = bill_df, bill_num = max_bills, text = search)\n",
    "    if bill_df is None: raise Exception(\"Error in your maximum bills input, did you input 0?\")\n",
    "    progress += 30\n",
    "\n",
    "    bill_text = concatenate_column(bill_df) # concatenating for modeling\n",
    "    progress += 30\n",
    "\n",
    "    bill_df.to_csv('temp_df.csv') # saving df\n",
    "    save_string_to_file(bill_text, 'temp_text.txt') # saving txt\n",
    "    progress += 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 400x100 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generating global figure for plotting results\n",
    "fig, ax = plt.subplots(figsize=(4,1))\n",
    "ax.set_xlabel('Iterations')\n",
    "ax.set_ylabel('Loss')\n",
    "\n",
    "# function to update loss value\n",
    "def update_loss_plot(loss_values):\n",
    "    ax.clear()\n",
    "    ax.plot(loss_values)\n",
    "    fig.canvas.draw()\n",
    "\n",
    "# list to store loss values\n",
    "all_losses_numpy = []\n",
    "\n",
    "# for evaluation, we will need to create global variable to store final model\n",
    "global_all_chars, global_num_chars = 0, 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def long_operation_thread_modeling(user_seq_len, user_hidden_state, user_iters, user_iter_update, user_lr, user_predicted_len, user_loss_func, user_optimizer_func):\n",
    "    global progress, message, net, all_losses_numpy, global_all_chars, global_num_chars\n",
    "\n",
    "    try: # loading saved text file\n",
    "        with open('temp_text.txt', 'r') as file:\n",
    "            bill_text = file.read()\n",
    "    except:\n",
    "        raise Exception(\"Training Halted: Make sure you have text scraped first!\")\n",
    "\n",
    "    # converting all values\n",
    "    user_seq_len = convert_to_int(user_seq_len)\n",
    "    user_hidden_state = convert_to_int(user_hidden_state)\n",
    "    user_iters = convert_to_int(user_iters)\n",
    "    user_iter_update = convert_to_int(user_iter_update)\n",
    "    user_lr = convert_to_float(user_lr)\n",
    "    user_predicted_len = convert_to_int(user_predicted_len)\n",
    "    numeric_inputs = [user_seq_len, user_hidden_state, user_iters, user_iter_update, user_lr, user_predicted_len]\n",
    "\n",
    "    # Checks for zeroes or nulls which can result from improper inputs\n",
    "    if all(var == 0 or var is None for var in numeric_inputs):\n",
    "        raise Exception(\"Training Halted: Ensure your numbers are correct!\")\n",
    "\n",
    "    # making sure bill_text is minimum length\n",
    "    if len(bill_text) <= user_seq_len: raise Exception(\"Training Halted: Character Size of your Dataset is too low for your Sequence Length.\")\n",
    "\n",
    "    # setting character info\n",
    "    all_chars       = string.printable # all possible characters\n",
    "    n_chars         = len(all_chars) # length of all possible characters\n",
    "    file            = bill_text # pointing as a file (just to make it easier to expand this later)\n",
    "    file = ''.join([char for char in file if char in all_chars]) # cleaning to prevent errors when one hotting\n",
    "    file_len        = len(file) # length of file/aka char length\n",
    "\n",
    "    print('Length of file: {}'.format(file_len))\n",
    "\n",
    "    # omitted but the option is there\n",
    "    # print('All possible characters: {}'.format(all_chars))\n",
    "    # print('Number of all possible characters: {}'.format(n_chars))\n",
    "\n",
    "    # initialize Network\n",
    "    net = Net()\n",
    "    net.set_n_chars(n_chars)\n",
    "    net.set_hidden_size(user_hidden_state) # setting the hidden layers\n",
    "    net.to(device) # setting the character length (from n_chars)\n",
    "\n",
    "    # Number of iterations.\n",
    "    # NOTE: You may reduce the number of training iterations if the training takes long.\n",
    "    iters       = user_iters  # Number of training iterations.\n",
    "    print_iters = user_iter_update    # Number of iterations for each log printing.\n",
    "\n",
    "    # The loss variables.\n",
    "    all_losses = [] # resets local list due to re-running of model\n",
    "    all_losses_numpy = [] # resets global np for plotting\n",
    "    loss_sum   = 0\n",
    "\n",
    "    # User selected optimizer and loss function + lr initialization\n",
    "    opt = get_optimizer(user_optimizer_func, user_lr, net)\n",
    "    loss_func = get_loss_function(user_loss_func)\n",
    "\n",
    "    # Training procedure.\n",
    "    for i in range(iters):\n",
    "        input, target = get_input_and_target(file = file, file_length = file_len, all_chars = all_chars, num_chars = n_chars, user_seq_length = user_seq_len) # Fetch input and target.\n",
    "        input, target = input.to(device), target.to(device) # Move to GPU memory.\n",
    "        loss      = train_step(net, opt, input, target, loss_func = loss_func)   # Calculate the loss.\n",
    "        loss_sum += loss                                  # Accumulate the loss.\n",
    "\n",
    "        # Print the log.\n",
    "        if i % print_iters == print_iters - 1:\n",
    "            print('iter:{}/{} loss:{}'.format(i, iters, loss_sum / print_iters))\n",
    "            print('generated sequence: {}\\n'.format(eval_step(net, all_chars = all_chars, num_chars = n_chars, predicted_len = user_predicted_len)))\n",
    "            progress = int((i / iters) * 100) # progress bar update\n",
    "\n",
    "            # Track the loss.\n",
    "            all_losses.append(loss_sum / print_iters)\n",
    "            all_losses_numpy = [tensor.detach().cpu().numpy() for tensor in all_losses]\n",
    "            loss_sum = 0\n",
    "\n",
    "    # setting n and all to global for repeated evaluation/generation\n",
    "    global_all_chars, global_num_chars = all_chars, n_chars"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "sg.theme_list()\n",
    "def release_the_gui():\n",
    "    # we're doing multithreading now! Basically just ensuring the GUI will work\n",
    "    global message, progress, net, all_losses_numpy, global_all_chars, global_num_chars\n",
    "    # there's no point in adding multiple threads for webscraping because it needs to be limited in timing\n",
    "    # else we will be kicked from CA Legis\n",
    "    # Also pytorch will be running on GPU so no need to multithread that, it's handled by pytorch\n",
    "\n",
    "    # variables needed for certain UI elements\n",
    "    year_ranges = [str(year) + '-' + str(year + 1) for year in range(1999, 2024, 2)] # bill year ranges\n",
    "    model_run_count = 0\n",
    "\n",
    "# --------------------- LAYOUT SECTION ---------------------\n",
    "    sg.theme(\"CustomTheme\") #I do like dark theme\n",
    "\n",
    "    # Making/setting the layout of the window. Just an input field and some buttons to run all functions in proper order at the user's whim (without allowing multiple clicks)\n",
    "\n",
    "    layout = [\n",
    "        [\n",
    "            sg.Text(\"Char RNN California Legislature Modeler\\n\", font=(\"Helvetica\", 20), text_color=\"white\", justification=\"center\")\n",
    "        ],\n",
    "        [\n",
    "            sg.Text(\"Note: Data must be loaded prior to training.\", font=(\"Helvetica\", 12), text_color=\"white\", background_color=None, justification=\"center\")\n",
    "        ],\n",
    "        [\n",
    "            sg.Column(\n",
    "                [\n",
    "                    [sg.Text(\"Scraping Settings\")],\n",
    "                    [sg.Text(\"Input search text here: \"), sg.InputText(key='-STRIN-', size=(30, 1))],\n",
    "                    [sg.Text(\"House: \"), sg.Combo(['Assembly', 'Senate', 'Both'], default_value='Assembly', key='-HOUSE-', readonly=True)],\n",
    "                    [sg.Text(\"Start Year Range: \"), sg.Combo(year_ranges, default_value='1999-2000', key='-START-YEAR-', readonly=True)],\n",
    "                    [sg.Text(\"End Year Range: \"), sg.Combo(year_ranges, default_value='2001-2002', key='-END-YEAR-', readonly=True)],\n",
    "                    [sg.Text(\"Number of Bills to Scrape: \"), sg.InputText(key='-MAX-BILLS-', size=(4, 1), default_text='1')],\n",
    "                    [sg.Output(size=(50, 10))]\n",
    "                ],\n",
    "                justification=\"left\",\n",
    "                element_justification=\"left\"\n",
    "            ),\n",
    "            sg.VSeperator(),\n",
    "            sg.Column(\n",
    "                [\n",
    "                        [sg.Text(\"Training Settings\")],\n",
    "                        [sg.Text(\"Loss Function: \"), sg.Combo(['Cross Entropy'], default_value='Cross Entropy', key='-LOSSFUNCT-', readonly=True)],\n",
    "                        [sg.Text(\"Optimizer: \"), sg.Combo(['Adam', 'SGD', 'RMS Prop', 'Adagrad'], default_value='Adam', key='-OPTIMIZER-', readonly=True)],\n",
    "                        [sg.Text(\"Learning Rate: \"), sg.InputText(key='-LEARNING-RATE-', size=(4, 1), default_text='0.05')],\n",
    "                        [sg.Text(\"Hidden Layer Size: \"), sg.InputText(key='-HIDDEN-LAYERS-', size=(4, 1), default_text='100')],\n",
    "                        [sg.Text(\"Sequence Length: \"), sg.InputText(key='-SEQ-LEN-', size=(4, 1), default_text='128'), sg.Text(\" Characters\")],\n",
    "                        [sg.Text(\"Iterations: \"), sg.InputText(key='-ITERATIONS-', size=(5, 1), default_text='20000')],\n",
    "                        [sg.Text(\"Iteration Update: \"), sg.InputText(key='-ITERATION-UPDATE-', size=(3, 1), default_text='100'), sg.Text(\" Iterations\")],\n",
    "                        [sg.Text(\"Prediction Length: \"), sg.InputText(key='-PREDICTED-LEN-', size=(3, 1), default_text='100'), sg.Text(\" Characters\")],\n",
    "                        [sg.Canvas(key='-CANVAS-')], # to plot loss in real time\n",
    "                        [sg.Text(\"Evaluate at: \"), sg.InputText(key='-EVAL-CHARS-', size=(3, 1), default_text='100'), sg.Button(\"Go\")]\n",
    "                        # Add other elements to the right of the line\n",
    "                ],\n",
    "                justification=\"right\",\n",
    "                element_justification=\"right\"\n",
    "            )\n",
    "        ],\n",
    "        [sg.Button(\"Scrape\"), sg.Button(\"Train\"), sg.Button(\"Save\", disabled=\"True\"), sg.Button(\"Exit\", button_color=(\"white\", \"red\"))],\n",
    "        [sg.Text('Work progress'), sg.ProgressBar(total, size=(20, 20), orientation='h', key='-PROG-')],\n",
    "    ]\n",
    "\n",
    "    window = sg.Window(\"CA Legal Char RNN\", layout) # creating new window to read (display) in while loop\n",
    "    figure_canvas_agg = None\n",
    "    thread = None # nothing is running in the separate thread right now\n",
    "\n",
    "    # --------------------- EVENT LOOP ---------------------\n",
    "\n",
    "    while True: # while the sg event/window is in use\n",
    "        event, values = window.read(timeout=100)\n",
    "        if event in (None, \"Exit\"): # Exit this loop if the exit button is clicked\n",
    "            break\n",
    "\n",
    "\n",
    "        if event == 'Scrape' and not thread:\n",
    "            house = values['-HOUSE-']\n",
    "            start_year_range = values['-START-YEAR-']\n",
    "            end_year_range = values['-END-YEAR-']\n",
    "            print(f'Beginning scraping process for {house} House/s for the sessions of {start_year_range} to {end_year_range}...\\n')\n",
    "            thread = threading.Thread(target=long_operation_thread_scraping, args=(house, start_year_range, end_year_range, values['-MAX-BILLS-'], values['-STRIN-'],), daemon=True)\n",
    "            thread.start()\n",
    "            continue\n",
    "\n",
    "\n",
    "        if event == 'Train' and not thread:\n",
    "            # user inputs\n",
    "            seq_len = values['-SEQ-LEN-']\n",
    "            hidden_layers = values['-HIDDEN-LAYERS-']\n",
    "            iterations = values['-ITERATIONS-']\n",
    "            learning_rate = values['-LEARNING-RATE-']\n",
    "            loss_funct = values['-LOSSFUNCT-']\n",
    "            optimizer_func = values['-OPTIMIZER-']\n",
    "            interation_update = values['-ITERATION-UPDATE-']\n",
    "            predicted_length = values['-PREDICTED-LEN-']\n",
    "            # print statement\n",
    "            print(f'Beginning training process for {optimizer_func} optimizer with loss function {loss_funct} at {learning_rate} learning rate for {iterations} iterations with {hidden_layers} hidden layers and {seq_len} character sequence length...\\n')\n",
    "            # Allow for Model Saving\n",
    "            window[\"Save\"].update(disabled=False)\n",
    "            window[\"Go\"].update(disabled=False)\n",
    "            # begin function\n",
    "            thread = threading.Thread(target=long_operation_thread_modeling, args=(seq_len, hidden_layers, iterations, interation_update, learning_rate, predicted_length, loss_funct, optimizer_func,), daemon=True)\n",
    "            thread.start()\n",
    "            model_run_count += 1 # keeps track of our models\n",
    "            continue\n",
    "\n",
    "        if event == 'Save' and not thread:\n",
    "            window[\"Save\"].update(disabled=True)\n",
    "            window[\"Scrape\"].update(disabled=True)\n",
    "            window[\"Train\"].update(disabled=True)\n",
    "            window[\"Go\"].update(disabled=True)\n",
    "            torch.save(net.state_dict(), f'model{model_run_count}.pth')\n",
    "            print(f\"Model State Dict Saved as {model_run_count}.\\n\")\n",
    "            window[\"Save\"].update(disabled=False)\n",
    "            window[\"Scrape\"].update(disabled=False)\n",
    "            window[\"Train\"].update(disabled=False)\n",
    "            window[\"Go\"].update(disabled=False)\n",
    "            continue\n",
    "\n",
    "        if event == 'Go' and not thread:\n",
    "            eval_char_size = convert_to_int(values['-EVAL-CHARS-'])\n",
    "            print(f\"Evaluating at {eval_char_size} characters:  \")\n",
    "            thread = threading.Thread(target=eval_step, args=(net, global_all_chars, global_num_chars, 'W', eval_char_size, True,), daemon=True)\n",
    "            thread.start()\n",
    "            continue\n",
    "\n",
    "        if figure_canvas_agg is None: # initialize the Plot\n",
    "            canvas = window['-CANVAS-'].TKCanvas\n",
    "            figure_canvas_agg = FigureCanvasTkAgg(fig, master=canvas)\n",
    "            figure_canvas_agg.draw()\n",
    "            figure_canvas_agg.get_tk_widget().pack(side='top', fill='both')\n",
    "\n",
    "        if thread:                                          # If thread is running\n",
    "            window['-PROG-'].update_bar(progress, total)    # update the progress bar with the current progress amount\n",
    "\n",
    "            # Draw the updated plot on the canvas\n",
    "            update_loss_plot(all_losses_numpy)\n",
    "\n",
    "            # disable buttons\n",
    "            window[\"Scrape\"].update(disabled=True)\n",
    "            window[\"Train\"].update(disabled=True)\n",
    "            window[\"Save\"].update(disabled=True)\n",
    "            window[\"Go\"].update(disabled=True)\n",
    "\n",
    "            thread.join(timeout=0)\n",
    "\n",
    "\n",
    "            if not thread.is_alive():                       # if the thread is finished/dead\n",
    "                window[\"Save\"].update(disabled=False)\n",
    "                window[\"Scrape\"].update(disabled=False)\n",
    "                window[\"Train\"].update(disabled=False)\n",
    "                window[\"Go\"].update(disabled=False)\n",
    "                thread, message, progress = None, '', 0  # reset variables for next run\n",
    "                window['-PROG-'].update_bar(0,0) # clear the progress bar\n",
    "                print('\\nFinished!\\n\\n') # Send complete message\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    window.close() # Once the loop is done, close the window ending this function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    release_the_gui()\n",
    "    exit()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}